{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sympy import symbols, sympify, Poly\n",
    "from collections import defaultdict\n",
    "\n",
    "def evaluate_polynomial(target_polynomial, dataset, observed_constants, observed_derivatives, measured_variables):\n",
    "    evaluated_values = []\n",
    "    \n",
    "    # Combine all variable names (constants, derivatives, and measured variables)\n",
    "    all_variables = observed_constants + observed_derivatives + measured_variables\n",
    "    \n",
    "    for i in range(dataset.shape[0]):\n",
    "        # Substitute values into the polynomial\n",
    "        polynomial = target_polynomial\n",
    "        for j, var in enumerate(all_variables):\n",
    "            # Replace variables with placeholders to avoid invalid syntax\n",
    "            polynomial = re.sub(rf'\\b{var}\\b', f'{var}_value', polynomial)\n",
    "        \n",
    "        # Replace '^' with '**' for exponentiation\n",
    "        polynomial = polynomial.replace('^', '**')\n",
    "\n",
    "        # Evaluate the polynomial\n",
    "        try:\n",
    "            # Parse the polynomial string into a symbolic expression\n",
    "            expr = sympify(polynomial)\n",
    "            \n",
    "            # Substitute numeric values into the expression\n",
    "            substitutions = {}\n",
    "            for j, var in enumerate(all_variables):\n",
    "                substitutions[symbols(f'{var}_value')] = dataset[i, j]\n",
    "            \n",
    "            expr = expr.subs(substitutions)\n",
    "            \n",
    "            # Evaluate the polynomial\n",
    "            value = float(expr.evalf())\n",
    "            evaluated_values.append(value)\n",
    "        except Exception as e:\n",
    "            evaluated_values.append(np.nan)  # Skip if evaluation fails\n",
    "            print(f\"Exception: {e}\")  # Debugging: Print the exception\n",
    "    \n",
    "    return np.array(evaluated_values)\n",
    "\n",
    "\n",
    "# Function to extract target polynomial, measured variables, observed constants, and observed derivatives\n",
    "def extract_info_from_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        content = file.readlines()\n",
    "    \n",
    "    # Extract target polynomial\n",
    "    target_polynomial_line = next(line for line in content if line.startswith('Target Polynomial:'))\n",
    "    target_polynomial = target_polynomial_line.split('Target Polynomial:')[1].strip()\n",
    "    \n",
    "    # Extract measured variables\n",
    "    measured_variables_line = next(line for line in content if line.startswith('Measured Variables:'))\n",
    "    measured_variables = eval(measured_variables_line.split('Measured Variables:')[1].strip())\n",
    "    \n",
    "    # Extract observed constants\n",
    "    observed_constants_line = next(line for line in content if line.startswith('Observed Constants:'))\n",
    "    observed_constants = eval(observed_constants_line.split('Observed Constants:')[1].strip())\n",
    "    \n",
    "    # Extract observed derivatives\n",
    "    observed_derivatives_line = next(line for line in content if line.startswith('Observed Derivatives:'))\n",
    "    observed_derivatives = eval(observed_derivatives_line.split('Observed Derivatives:')[1].strip())\n",
    "    \n",
    "    return target_polynomial, measured_variables, observed_constants, observed_derivatives\n",
    "\n",
    "def generate_dataset(target_polynomial, measured_variables, observed_constants, observed_derivatives, constant_data=True, derivative_data=True):\n",
    "    # Initialize dataset as a 2D array with 1000 rows and 0 columns\n",
    "    dataset = np.zeros((1000, 0))  # Start with an empty 2D array\n",
    "\n",
    "    # Step 2a: Generate data for constants\n",
    "    if constant_data and observed_constants:  # Only proceed if constants are provided\n",
    "        constant_values = {const: np.random.uniform(0, 10) for const in observed_constants}  # Sample once\n",
    "        constant_data_matrix = np.array([[constant_values[const]] * 1000 for const in observed_constants]).T  # Repeat 1000 times\n",
    "        dataset = np.hstack((dataset, constant_data_matrix))  # Append constant data\n",
    "    elif not constant_data and observed_constants:\n",
    "        constant_values = {const: np.random.normal(5, 3, 1000) for const in observed_constants}  # Generate 1000 samples per constant\n",
    "        constant_data_matrix = np.column_stack([constant_values[const] for const in observed_constants])  # Stack properly\n",
    "        dataset = np.hstack((dataset, constant_data_matrix))  # Append constant data\n",
    "\n",
    "\n",
    "    derivative_dependent_variable = []\n",
    "    # Step 2b: Generate data for derivatives\n",
    "    if derivative_data and 'd2xdt2' in observed_derivatives:  # Only proceed if derivatives are provided\n",
    "        if 'd1' in measured_variables:\n",
    "            # Generate data for d1 and its derivative d2xdt2\n",
    "            d1_data = np.random.normal(5, 3, 1000)\n",
    "            d2xdt2_data = np.diff(d1_data, append=d1_data[0])  # Differences with loop-around\n",
    "            \n",
    "            # Append d1 and d2xdt2 to the dataset\n",
    "            dataset = np.hstack((dataset, d1_data.reshape(-1, 1), d2xdt2_data.reshape(-1, 1)))\n",
    "            \n",
    "            # Remove d1 from measured_variables to avoid double-generation\n",
    "            measured_variables.remove('d1')\n",
    "            derivative_dependent_variable.append('d1')\n",
    "        elif 'd2' in measured_variables:\n",
    "            # Generate data for d2 and its derivative d2xdt2\n",
    "            d2_data = np.random.normal(5, 3, 1000)\n",
    "            d2xdt2_data = np.diff(d2_data, append=d2_data[0])  # Differences with loop-around\n",
    "            \n",
    "            # Append d2 and d2xdt2 to the dataset\n",
    "            dataset = np.hstack((dataset, d2_data.reshape(-1, 1), d2xdt2_data.reshape(-1, 1)))\n",
    "            \n",
    "            # Remove d2 from measured_variables to avoid double-generation\n",
    "            measured_variables.remove('d2')\n",
    "            derivative_dependent_variable.append('d2')\n",
    "        else:\n",
    "            # If neither d1 nor d2 is present, generate data for d2xdt2 directly\n",
    "            d2xdt2_data = np.random.normal(0, 5, 1000)\n",
    "            dataset = np.hstack((dataset, d2xdt2_data.reshape(-1, 1)))\n",
    "    \n",
    "    # Step 2c: Sort measured variables by degree in target polynomial\n",
    "    degree_dict = defaultdict(int)\n",
    "    for var in measured_variables:\n",
    "        matches = re.findall(rf'{var}\\^(\\d+)', target_polynomial)\n",
    "        if matches:\n",
    "            degree_dict[var] = sum(int(exp) for exp in matches)\n",
    "        else:\n",
    "            degree_dict[var] = 1\n",
    "    sorted_variables = sorted(measured_variables, key=lambda x: degree_dict[x], reverse=True)\n",
    "    \n",
    "    # Generate data for all but the last variable\n",
    "    for var in sorted_variables[:-1]:\n",
    "        var_data = np.random.normal(5, 3, 1000)\n",
    "        dataset = np.hstack((dataset, var_data.reshape(-1, 1)))\n",
    "    \n",
    "    # Step 2d: Generate data for the last variable\n",
    "    last_var = sorted_variables[-1]\n",
    "    last_var_symbol = symbols(last_var)  # Convert to symbolic variable\n",
    "\n",
    "    roots_column = np.zeros((dataset.shape[0], 1)) * np.nan  # Initialize with NaN\n",
    "\n",
    "    complex_count = 0\n",
    "    evaluation_fail_count = 0\n",
    "\n",
    "    for i in range(1000):\n",
    "        # Substitute all known values into the polynomial at once\n",
    "        polynomial = target_polynomial\n",
    "        for j, var in enumerate(observed_constants + observed_derivatives + derivative_dependent_variable + sorted_variables[:-1]):\n",
    "            # Replace variables with placeholders to avoid invalid syntax\n",
    "            polynomial = re.sub(rf'\\b{var}\\b', f'{var}_value', polynomial)\n",
    "        \n",
    "        # Replace '^' with '**' for exponentiation\n",
    "        polynomial = polynomial.replace('^', '**')\n",
    "\n",
    "        # Convert the polynomial into a symbolic expression\n",
    "        try:\n",
    "            expr = sympify(polynomial)\n",
    "            \n",
    "            # Substitute numeric values into the expression\n",
    "            substitutions = {}\n",
    "            for j, var in enumerate(observed_constants + observed_derivatives + derivative_dependent_variable + sorted_variables[:-1]):\n",
    "                substitutions[symbols(f'{var}_value')] = dataset[i, j]\n",
    "            \n",
    "            expr = expr.subs(substitutions)\n",
    "            \n",
    "            # Extract coefficients of the polynomial in the last variable\n",
    "            poly = Poly(expr, last_var_symbol)\n",
    "            coefficients = poly.all_coeffs()\n",
    "            \n",
    "            # Solve for the roots\n",
    "            roots = np.roots(coefficients)\n",
    "            \n",
    "            # Filter real roots\n",
    "            real_roots = roots[np.isreal(roots)].real\n",
    "            \n",
    "            if len(real_roots) > 0:\n",
    "                roots_column[i] = real_roots[0]  # Use the first real root\n",
    "            else:\n",
    "                complex_count += 1\n",
    "        except Exception as e:\n",
    "            evaluation_fail_count += 1\n",
    "            print(f\"An exception occurred: {e}\")  # Skip if polynomial evaluation fails   \n",
    "\n",
    "    # Append the roots column to the dataset\n",
    "    dataset = np.hstack((dataset, roots_column))\n",
    "\n",
    "    # Remove rows with NaN values\n",
    "    dataset = dataset[~np.isnan(dataset).any(axis=1)] \n",
    "    print(\"Complex roots thrown out: \", complex_count)\n",
    "    print(\"Number of failed evaluations: \", evaluation_fail_count)  \n",
    "    \n",
    "    return dataset, derivative_dependent_variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(target_polynomial, measured_variables, observed_constants, observed_derivatives, constant_data=True, derivative_data=True, region=[1,5]):\n",
    "    # Initialize dataset as a 2D array with 1000 rows and 0 columns\n",
    "    dataset = np.zeros((1000, 0))  # Start with an empty 2D array\n",
    "\n",
    "    # Step 2a: Generate data for constants\n",
    "    if constant_data and observed_constants:  # Only proceed if constants are provided\n",
    "        constant_values = {const: np.random.uniform(0, 10) for const in observed_constants}  # Sample once\n",
    "        constant_data_matrix = np.array([[constant_values[const]] * 1000 for const in observed_constants]).T  # Repeat 1000 times\n",
    "        dataset = np.hstack((dataset, constant_data_matrix))  # Append constant data\n",
    "    elif not constant_data and observed_constants:\n",
    "        constant_values = {const: np.random.uniform(region[0], region[1], 1000) for const in observed_constants}  # Generate 1000 samples per constant\n",
    "        constant_data_matrix = np.column_stack([constant_values[const] for const in observed_constants])  # Stack properly\n",
    "        dataset = np.hstack((dataset, constant_data_matrix))  # Append constant data\n",
    "\n",
    "    derivative_dependent_variable = []\n",
    "    derivative_data_matrix = []\n",
    "    \n",
    "    # Step 2b: Generate data for derivatives only if needed\n",
    "    if derivative_data:\n",
    "        if 'd1' in measured_variables and ('dx1dt' in observed_derivatives or 'd2x1dt2' in observed_derivatives):\n",
    "            d1_data = np.random.uniform(region[0], region[1], 1000)\n",
    "            dx1dt_data = np.diff(d1_data, append=d1_data[0]) if 'dx1dt' in observed_derivatives else None\n",
    "            if 'dx1dt' in observed_derivatives:\n",
    "                d2x1dt2_data = np.diff(dx1dt_data, append=dx1dt_data[0]) if 'd2x1dt2' in observed_derivatives else None\n",
    "            else: \n",
    "                d2x1dt2_data = np.random.uniform(region[0],region[1], 1000) if 'd2x1dt2' in observed_derivatives else None\n",
    "            \n",
    "            if dx1dt_data is not None:\n",
    "                derivative_data_matrix.append(dx1dt_data)\n",
    "            if d2x1dt2_data is not None:\n",
    "                derivative_data_matrix.append(d2x1dt2_data)\n",
    "\n",
    "        elif 'd1' not in measured_variables and ('dx1dt' in observed_derivatives or 'd2x1dt2' in observed_derivatives):\n",
    "            dx1dt_data = np.random.uniform(region[0],region[1], 1000)\n",
    "            if 'dx1dt' in observed_derivatives:\n",
    "                d2x1dt2_data = np.diff(dx1dt_data, append=dx1dt_data[0]) if 'd2x1dt2' in observed_derivatives else None\n",
    "            else: \n",
    "                d2x1dt2_data = np.random.uniform(region[0],region[1], 1000) if 'd2x1dt2' in observed_derivatives else None\n",
    "            if dx1dt_data is not None:\n",
    "                derivative_data_matrix.append(dx1dt_data)\n",
    "            if d2x1dt2_data is not None:\n",
    "                derivative_data_matrix.append(d2x1dt2_data)\n",
    "        \n",
    "        if 'd2' in measured_variables and ('dx2dt' in observed_derivatives or 'd2x2dt2' in observed_derivatives):\n",
    "            d2_data = np.random.uniform(region[0], region[1], 1000)\n",
    "            dx2dt_data = np.diff(d2_data, append=d2_data[0]) if 'dx2dt' in observed_derivatives else None\n",
    "            if 'dx2dt' in observed_derivatives:\n",
    "                d2x2dt2_data = np.diff(dx2dt_data, append=dx2dt_data[0]) if 'd2x2dt2' in observed_derivatives else None\n",
    "            else: \n",
    "                d2x2dt2_data = np.random.uniform(region[0],region[1], 1000) if 'd2x2dt2' in observed_derivatives else None\n",
    "            \n",
    "            if dx2dt_data is not None:\n",
    "                derivative_data_matrix.append(dx2dt_data)\n",
    "            if d2x2dt2_data is not None:\n",
    "                derivative_data_matrix.append(d2x2dt2_data)\n",
    "\n",
    "        elif 'd2' not in measured_variables and ('dx2dt' in observed_derivatives or 'd2x2dt2' in observed_derivatives):\n",
    "            dx2dt_data = np.random.uniform(region[0],region[1], 1000)\n",
    "            if 'dx2dt' in observed_derivatives:\n",
    "                d2x2dt2_data = np.diff(dx2dt_data, append=dx2dt_data[0]) if 'd2x2dt2' in observed_derivatives else None\n",
    "            else: \n",
    "                d2x2dt2_data = np.random.uniform(region[0],region[1], 1000) if 'd2x2dt2' in observed_derivatives else None\n",
    "\n",
    "            if dx2dt_data is not None:\n",
    "                derivative_data_matrix.append(dx2dt_data)\n",
    "            if d2x2dt2_data is not None:\n",
    "                derivative_data_matrix.append(d2x2dt2_data)\n",
    "\n",
    "        if 'd1' in measured_variables and ('dx1dt' in observed_derivatives or 'd2x1dt2' in observed_derivatives):\n",
    "            derivative_data_matrix.append(d1_data)\n",
    "            measured_variables.remove('d1')\n",
    "            derivative_dependent_variable.append('d1')\n",
    "        if 'd2' in measured_variables and ('dx2dt' in observed_derivatives or 'd2x2dt2' in observed_derivatives):\n",
    "            derivative_data_matrix.append(d2_data)\n",
    "            measured_variables.remove('d2')\n",
    "            derivative_dependent_variable.append('d2')\n",
    "\n",
    "    \n",
    "    if derivative_data_matrix:\n",
    "        dataset = np.hstack((dataset, np.column_stack(derivative_data_matrix)))\n",
    "    \n",
    "    # Step 2c: Sort measured variables by degree in target polynomial\n",
    "    degree_dict = defaultdict(int)\n",
    "    for var in measured_variables:\n",
    "        matches = re.findall(rf'{var}\\^(\\d+)', target_polynomial)\n",
    "        if matches:\n",
    "            degree_dict[var] = sum(int(exp) for exp in matches)\n",
    "        else:\n",
    "            degree_dict[var] = 1\n",
    "    sorted_variables = sorted(measured_variables, key=lambda x: degree_dict[x], reverse=True)\n",
    "\n",
    "    # Generate data for all but the last variable\n",
    "    for var in sorted_variables[:-1]:\n",
    "        var_data = np.random.uniform(region[0], region[1], 1000)\n",
    "        dataset = np.hstack((dataset, var_data.reshape(-1, 1)))\n",
    "\n",
    "    # Step 2d: Generate data for the last variable\n",
    "    last_var = sorted_variables[-1]\n",
    "    last_var_symbol = symbols(last_var)  # Convert to symbolic variable\n",
    "\n",
    "    roots_column = np.zeros((dataset.shape[0], 1)) * np.nan  # Initialize with NaN\n",
    "\n",
    "    complex_count = 0\n",
    "    evaluation_fail_count = 0\n",
    "\n",
    "    for i in range(1000):\n",
    "        # Substitute all known values into the polynomial at once\n",
    "        polynomial = target_polynomial\n",
    "        for j, var in enumerate(observed_constants + observed_derivatives + derivative_dependent_variable + sorted_variables[:-1]):\n",
    "            # Replace variables with placeholders to avoid invalid syntax\n",
    "            polynomial = re.sub(rf'\\b{var}\\b', f'{var}_value', polynomial)\n",
    "\n",
    "        # Replace '^' with '**' for exponentiation\n",
    "        polynomial = polynomial.replace('^', '**')\n",
    "\n",
    "        # Convert the polynomial into a symbolic expression\n",
    "    #try:\n",
    "        expr = sympify(polynomial)\n",
    "        \n",
    "        # Substitute numeric values into the expression\n",
    "        substitutions = {}\n",
    "        for j, var in enumerate(observed_constants + observed_derivatives + derivative_dependent_variable + sorted_variables[:-1]):\n",
    "            substitutions[symbols(f'{var}_value')] = dataset[i, j]\n",
    "        \n",
    "        expr = expr.subs(substitutions)\n",
    "        \n",
    "        # Extract coefficients of the polynomial in the last variable\n",
    "        poly = Poly(expr, last_var_symbol)\n",
    "        coefficients = poly.all_coeffs()\n",
    "\n",
    "        # Solve for the roots\n",
    "        roots = np.roots(coefficients)\n",
    "        \n",
    "        # Filter real roots\n",
    "        real_roots = roots[np.isreal(roots)].real\n",
    "        \n",
    "        if len(real_roots) > 0:\n",
    "            roots_column[i] = real_roots[0]  # Use the first real root\n",
    "        else:\n",
    "            complex_count += 1\n",
    "    #except Exception as e:\n",
    "        evaluation_fail_count += 1\n",
    "        #print(f\"An exception occurred: {e}\")  # Skip if polynomial evaluation fails   \n",
    "\n",
    "    # Append the roots column to the dataset\n",
    "    dataset = np.hstack((dataset, roots_column))\n",
    "\n",
    "    # Remove rows with NaN values\n",
    "    dataset = dataset[~np.isnan(dataset).any(axis=1)] \n",
    "    print(\"Complex roots thrown out: \", complex_count)\n",
    "    print(\"Number of failed evaluations: \", evaluation_fail_count)  \n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def generate_dataset_no_der(target_polynomial, measured_variables, observed_constants, constant_data=True, region=[1,5]):\n",
    "    # Initialize dataset as a 2D array with 1000 rows and 0 columns\n",
    "    dataset = np.zeros((1000, 0))  # Start with an empty 2D array\n",
    "\n",
    "    # Step 2a: Generate data for constants\n",
    "    if constant_data and observed_constants:  # Only proceed if constants are provided\n",
    "        constant_values = {const: np.random.uniform(0, 10) for const in observed_constants}  # Sample once\n",
    "        constant_data_matrix = np.array([[constant_values[const]] * 1000 for const in observed_constants]).T  # Repeat 1000 times\n",
    "        dataset = np.hstack((dataset, constant_data_matrix))  # Append constant data\n",
    "    elif not constant_data and observed_constants:\n",
    "        constant_values = {const: np.random.uniform(region[0], region[1], 1000) for const in observed_constants}  # Generate 1000 samples per constant\n",
    "        constant_data_matrix = np.column_stack([constant_values[const] for const in observed_constants])  # Stack properly\n",
    "        dataset = np.hstack((dataset, constant_data_matrix))  # Append constant data\n",
    "\n",
    "    \n",
    "    # Step 2c: Sort measured variables by degree in target polynomial\n",
    "    degree_dict = defaultdict(int)\n",
    "    for var in measured_variables:\n",
    "        matches = re.findall(rf'{var}\\^(\\d+)', target_polynomial)\n",
    "        if matches:\n",
    "            degree_dict[var] = sum(int(exp) for exp in matches)\n",
    "        else:\n",
    "            degree_dict[var] = 1\n",
    "    sorted_variables = sorted(measured_variables, key=lambda x: degree_dict[x], reverse=True)\n",
    "\n",
    "    # Generate data for all but the last variable\n",
    "    for var in sorted_variables[:-1]:\n",
    "        var_data = np.random.uniform(region[0], region[1], 1000)\n",
    "        dataset = np.hstack((dataset, var_data.reshape(-1, 1)))\n",
    "\n",
    "    # Step 2d: Generate data for the last variable\n",
    "    last_var = sorted_variables[-1]\n",
    "    last_var_symbol = symbols(last_var)  # Convert to symbolic variable\n",
    "\n",
    "    roots_column = np.zeros((dataset.shape[0], 1)) * np.nan  # Initialize with NaN\n",
    "\n",
    "    complex_count = 0\n",
    "    evaluation_fail_count = 0\n",
    "\n",
    "    for i in range(1000):\n",
    "        # Substitute all known values into the polynomial at once\n",
    "        polynomial = target_polynomial\n",
    "        for j, var in enumerate(observed_constants + sorted_variables[:-1]):\n",
    "            # Replace variables with placeholders to avoid invalid syntax\n",
    "            polynomial = re.sub(rf'\\b{var}\\b', f'{var}_value', polynomial)\n",
    "\n",
    "        # Replace '^' with '**' for exponentiation\n",
    "        polynomial = polynomial.replace('^', '**')\n",
    "\n",
    "        # Convert the polynomial into a symbolic expression\n",
    "    #try:\n",
    "        expr = sympify(polynomial)\n",
    "        \n",
    "        # Substitute numeric values into the expression\n",
    "        substitutions = {}\n",
    "        for j, var in enumerate(observed_constants + sorted_variables[:-1]):\n",
    "            substitutions[symbols(f'{var}_value')] = dataset[i, j]\n",
    "        \n",
    "        expr = expr.subs(substitutions)\n",
    "        \n",
    "        # Extract coefficients of the polynomial in the last variable\n",
    "        poly = Poly(expr, last_var_symbol)\n",
    "        coefficients = poly.all_coeffs()\n",
    "\n",
    "        # Solve for the roots\n",
    "        roots = np.roots(coefficients)\n",
    "        \n",
    "        # Filter real roots\n",
    "        real_roots = roots[np.isreal(roots)].real\n",
    "        \n",
    "        if len(real_roots) > 0:\n",
    "            roots_column[i] = real_roots[0]  # Use the first real root\n",
    "        else:\n",
    "            complex_count += 1\n",
    "    #except Exception as e:\n",
    "        evaluation_fail_count += 1\n",
    "        #print(f\"An exception occurred: {e}\")  # Skip if polynomial evaluation fails   \n",
    "\n",
    "    # Append the roots column to the dataset\n",
    "    dataset = np.hstack((dataset, roots_column))\n",
    "\n",
    "    # Remove rows with NaN values\n",
    "    dataset = dataset[~np.isnan(dataset).any(axis=1)] \n",
    "    print(\"Complex roots thrown out: \", complex_count)\n",
    "    print(\"Number of failed evaluations: \", evaluation_fail_count)  \n",
    "    \n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*m1^2*G*d1*Fg-4*m1^2*G*Fg*m2+4*m1*d1^2*Fg^2+3*d1*Fg^2*m2 ['m1', 'd1', 'Fg', 'm2'] ['G'] []\n",
      "Complex roots thrown out:  0\n",
      "Number of failed evaluations:  1000\n",
      "['m1', 'd1', 'Fg', 'm2']\n",
      "Exception: index 5 is out of bounds for axis 1 with size 5\n",
      "Exception: index 5 is out of bounds for axis 1 with size 5\n",
      "Exception: index 5 is out of bounds for axis 1 with size 5\n",
      "Exception: index 5 is out of bounds for axis 1 with size 5\n",
      "Exception: index 5 is out of bounds for axis 1 with size 5\n",
      "Evaluation:  nan\n",
      "Generated dataset for system90.txt with shape (1000, 5)\n",
      "File system91.txt does not exist. Skipping iteration 91.\n",
      "File system92.txt does not exist. Skipping iteration 92.\n",
      "File system93.txt does not exist. Skipping iteration 93.\n",
      "40*m2^3*G+15*m2^2*d1^2*G+60*m2^2*d1*G+60*m2^2*G-16*m2*d1*Fg ['m2', 'd1', 'Fg'] ['G'] []\n",
      "Complex roots thrown out:  0\n",
      "Number of failed evaluations:  1000\n",
      "['m2', 'd1', 'Fg']\n",
      "Exception: index 4 is out of bounds for axis 1 with size 4\n",
      "Exception: index 4 is out of bounds for axis 1 with size 4\n",
      "Exception: index 4 is out of bounds for axis 1 with size 4\n",
      "Exception: index 4 is out of bounds for axis 1 with size 4\n",
      "Exception: index 4 is out of bounds for axis 1 with size 4\n",
      "Evaluation:  nan\n",
      "Generated dataset for system94.txt with shape (1000, 4)\n",
      "File system95.txt does not exist. Skipping iteration 95.\n",
      "File system96.txt does not exist. Skipping iteration 96.\n",
      "File system97.txt does not exist. Skipping iteration 97.\n",
      "File system98.txt does not exist. Skipping iteration 98.\n",
      "File system99.txt does not exist. Skipping iteration 99.\n",
      "File system100.txt does not exist. Skipping iteration 100.\n",
      "d1*m2^3-5*d1*m2^2+4*d1*m2 ['m1', 'G', 'w', 'd1', 'm2'] [] []\n",
      "Complex roots thrown out:  0\n",
      "Number of failed evaluations:  1000\n",
      "['m1', 'G', 'w', 'd1', 'm2']\n",
      "Exception: index 5 is out of bounds for axis 1 with size 5\n",
      "Exception: index 5 is out of bounds for axis 1 with size 5\n",
      "Exception: index 5 is out of bounds for axis 1 with size 5\n",
      "Exception: index 5 is out of bounds for axis 1 with size 5\n",
      "Exception: index 5 is out of bounds for axis 1 with size 5\n",
      "Evaluation:  nan\n",
      "Generated dataset for system101.txt with shape (1000, 5)\n",
      "2*Fg*m2^3+3*Fg*m2^2+3*Fg*m2+3*Fg ['d1', 'Fg', 'm2'] ['G'] []\n",
      "Complex roots thrown out:  0\n",
      "Number of failed evaluations:  1000\n",
      "['d1', 'Fg', 'm2']\n",
      "Exception: index 4 is out of bounds for axis 1 with size 4\n",
      "Exception: index 4 is out of bounds for axis 1 with size 4\n",
      "Exception: index 4 is out of bounds for axis 1 with size 4\n",
      "Exception: index 4 is out of bounds for axis 1 with size 4\n",
      "Exception: index 4 is out of bounds for axis 1 with size 4\n",
      "Evaluation:  nan\n",
      "Generated dataset for system102.txt with shape (1000, 4)\n",
      "File system103.txt does not exist. Skipping iteration 103.\n",
      "File system104.txt does not exist. Skipping iteration 104.\n",
      "32*Fg*d1^3+96*Fg*d1^2-126*Fg*d1+81*Fg ['Fg', 'd1'] ['G'] []\n",
      "Complex roots thrown out:  0\n",
      "Number of failed evaluations:  1000\n",
      "['Fg', 'd1']\n",
      "Exception: index 3 is out of bounds for axis 1 with size 3\n",
      "Exception: index 3 is out of bounds for axis 1 with size 3\n",
      "Exception: index 3 is out of bounds for axis 1 with size 3\n",
      "Exception: index 3 is out of bounds for axis 1 with size 3\n",
      "Exception: index 3 is out of bounds for axis 1 with size 3\n",
      "Evaluation:  nan\n",
      "Generated dataset for system105.txt with shape (1000, 3)\n",
      "File system106.txt does not exist. Skipping iteration 106.\n",
      "File system107.txt does not exist. Skipping iteration 107.\n",
      "File system108.txt does not exist. Skipping iteration 108.\n",
      "File system109.txt does not exist. Skipping iteration 109.\n"
     ]
    }
   ],
   "source": [
    "# Main script\n",
    "output_directory = 'target_polynomial_benchmark/data/'\n",
    "if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "input_directory = 'target_polynomial_benchmark/'\n",
    "\n",
    "n = 110\n",
    "np.random.seed(42)\n",
    "\n",
    "for i in range(90,n):\n",
    "    filename = f'system{i}.txt'\n",
    "    filepath = os.path.join(input_directory, filename)\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"File {filename} does not exist. Skipping iteration {i}.\")\n",
    "        continue\n",
    "    \n",
    "    # Extract info from file\n",
    "    target_polynomial, measured_variables, observed_constants, observed_derivatives = extract_info_from_file(filepath)\n",
    "    print(target_polynomial,measured_variables,observed_constants,observed_derivatives)\n",
    "    if observed_derivatives == []:\n",
    "         observed_derivatives = ['']\n",
    "    # Generate dataset\n",
    "    r1 = np.random.randint(0, 15)\n",
    "    region = [r1,r1+5]\n",
    "    \n",
    "    #dataset = generate_dataset(target_polynomial, measured_variables.copy(), observed_constants, observed_derivatives, True, False, region)\n",
    "    dataset = generate_dataset_no_der(target_polynomial, measured_variables.copy(), observed_constants, True, region)\n",
    "\n",
    "    if len(dataset) == 0:\n",
    "        print(\"No real roots found for system \",  i ,\". Skipping\")\n",
    "        continue\n",
    "    # Save dataset to file\n",
    "    np.savetxt(os.path.join(output_directory, f'numeric_data_{i}.dat'), dataset, delimiter=' ')\n",
    "    print(measured_variables)\n",
    "    print(\"Evaluation: \", sum(evaluate_polynomial(target_polynomial,dataset[0:5],observed_constants,observed_derivatives,measured_variables)))\n",
    "    print(f\"Generated dataset for {filename} with shape {dataset.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File numeric_data_91.dat does not exist. Skipping iteration 91.\n",
      "File numeric_data_92.dat does not exist. Skipping iteration 92.\n",
      "File numeric_data_93.dat does not exist. Skipping iteration 93.\n",
      "File numeric_data_95.dat does not exist. Skipping iteration 95.\n",
      "File numeric_data_96.dat does not exist. Skipping iteration 96.\n",
      "File numeric_data_97.dat does not exist. Skipping iteration 97.\n",
      "File numeric_data_98.dat does not exist. Skipping iteration 98.\n",
      "File numeric_data_99.dat does not exist. Skipping iteration 99.\n",
      "File numeric_data_100.dat does not exist. Skipping iteration 100.\n",
      "File numeric_data_103.dat does not exist. Skipping iteration 103.\n",
      "File numeric_data_104.dat does not exist. Skipping iteration 104.\n",
      "File numeric_data_106.dat does not exist. Skipping iteration 106.\n",
      "File numeric_data_107.dat does not exist. Skipping iteration 107.\n",
      "File numeric_data_108.dat does not exist. Skipping iteration 108.\n",
      "File numeric_data_109.dat does not exist. Skipping iteration 109.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to add noise to the data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def add_gaussian_noise(input_file, output_file, epsilon):\n",
    "    # Load data\n",
    "    data = np.loadtxt(input_file)\n",
    "        \n",
    "    # Generate Gaussian noise with standard deviation as 5% of the column's mean\n",
    "    noise = np.random.normal(0, np.abs(np.mean(data[:,-1])) * epsilon, len(data[:,-1]))\n",
    "    \n",
    "    # Apply noise only to non-constant columns\n",
    "    \n",
    "    data[:, -1] += noise\n",
    "    \n",
    "    # Save to output file\n",
    "    np.savetxt(output_file, data, fmt='%.18e')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    epsilon = 1e-1\n",
    "    input_directory = 'target_polynomial_benchmark/data/'\n",
    "    n = 110\n",
    "    for i in range(90,n):\n",
    "\n",
    "        filename = f'numeric_data_{i}.dat'\n",
    "        input_file = os.path.join(input_directory, filename)\n",
    "        if not os.path.exists(input_file):\n",
    "            print(f\"File {filename} does not exist. Skipping iteration {i}.\")\n",
    "            continue\n",
    "        output_directory = f\"target_polynomial_benchmark/data_noisy/{epsilon}/\"\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "        \n",
    "        output_file = os.path.join(output_directory, filename)\n",
    "        add_gaussian_noise(input_file, output_file,epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted 'target_polynomial_benchmark/data_noisy/0.0001/numeric_data_90.dat' to 'target_polynomial_benchmark/data_shortened_noisy/0.0001/numeric_data_90.dat'\n",
      "File numeric_data_91.dat does not exist. Skipping iteration 91.\n",
      "File numeric_data_92.dat does not exist. Skipping iteration 92.\n",
      "File numeric_data_93.dat does not exist. Skipping iteration 93.\n",
      "Successfully converted 'target_polynomial_benchmark/data_noisy/0.0001/numeric_data_94.dat' to 'target_polynomial_benchmark/data_shortened_noisy/0.0001/numeric_data_94.dat'\n",
      "File numeric_data_95.dat does not exist. Skipping iteration 95.\n",
      "File numeric_data_96.dat does not exist. Skipping iteration 96.\n",
      "File numeric_data_97.dat does not exist. Skipping iteration 97.\n",
      "File numeric_data_98.dat does not exist. Skipping iteration 98.\n",
      "File numeric_data_99.dat does not exist. Skipping iteration 99.\n",
      "File numeric_data_100.dat does not exist. Skipping iteration 100.\n",
      "Successfully converted 'target_polynomial_benchmark/data_noisy/0.0001/numeric_data_101.dat' to 'target_polynomial_benchmark/data_shortened_noisy/0.0001/numeric_data_101.dat'\n",
      "Successfully converted 'target_polynomial_benchmark/data_noisy/0.0001/numeric_data_102.dat' to 'target_polynomial_benchmark/data_shortened_noisy/0.0001/numeric_data_102.dat'\n",
      "File numeric_data_103.dat does not exist. Skipping iteration 103.\n",
      "File numeric_data_104.dat does not exist. Skipping iteration 104.\n",
      "Successfully converted 'target_polynomial_benchmark/data_noisy/0.0001/numeric_data_105.dat' to 'target_polynomial_benchmark/data_shortened_noisy/0.0001/numeric_data_105.dat'\n",
      "File numeric_data_106.dat does not exist. Skipping iteration 106.\n",
      "File numeric_data_107.dat does not exist. Skipping iteration 107.\n",
      "File numeric_data_108.dat does not exist. Skipping iteration 108.\n",
      "File numeric_data_109.dat does not exist. Skipping iteration 109.\n"
     ]
    }
   ],
   "source": [
    "# You can run this cell if you want to reduce the amount of data you have\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def shorten_data(input_file, output_file=None):\n",
    "\n",
    "    try:\n",
    "        # Convert input path to Path object\n",
    "        input_path = Path(input_file)\n",
    "        \n",
    "        # Generate output filename if not provided\n",
    "        if output_file is None:\n",
    "            output_file = input_path.stem + '_converted' + input_path.suffix\n",
    "        \n",
    "        # Check if input file exists\n",
    "        if not input_path.exists():\n",
    "            raise FileNotFoundError(f\"Input file '{input_file}' not found\")\n",
    "        \n",
    "        # Process the file line by line\n",
    "        with open(input_path, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "            for i, line in enumerate(infile):\n",
    "                # Replace commas with spaces and write to output file\n",
    "                converted_line = line.strip()\n",
    "                outfile.write(converted_line + '\\n')\n",
    "                if i ==100:\n",
    "                    break\n",
    "                \n",
    "        print(f\"Successfully converted '{input_file}' to '{output_file}'\")\n",
    "        return output_file\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(f\"Error: Permission denied while accessing files\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    input_directory = 'target_polynomial_benchmark/data_noisy/0.0001'\n",
    "    n = 110\n",
    "    for i in range(90,n):\n",
    "        filename = f'numeric_data_{i}.dat'\n",
    "        filepath = os.path.join(input_directory, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"File {filename} does not exist. Skipping iteration {i}.\")\n",
    "            continue\n",
    "        output_directory = \"target_polynomial_benchmark/data_shortened_noisy/0.0001/\"\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "        output_filepath = os.path.join(output_directory, filename)\n",
    "        \n",
    "        shorten_data(filepath, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_hilbert_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
